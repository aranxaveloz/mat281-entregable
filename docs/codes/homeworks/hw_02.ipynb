{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aPMU15_niNl"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fralfaro/MAT281/blob/main/docs/homeworks/hw_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "# MAT281 - Tarea N°02\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjNUeXidniNq"
      },
      "source": [
        "## Objetivos de la Tarea\n",
        "\n",
        "El propósito de esta tarea es aplicar técnicas de **Machine Learning** con Python a dos contextos distintos:  \n",
        "1) el análisis del impacto del COVID-19 en el aprendizaje digital (LearnPlatform),  \n",
        "2) la predicción de supervivencia en el Titanic.\n",
        "\n",
        "### Objetivos específicos:\n",
        "\n",
        "1. **Preparar los datos**: integrar, limpiar y transformar los datasets para que puedan ser utilizados en modelos de aprendizaje automático.  \n",
        "\n",
        "2. **Explorar patrones relevantes**: analizar variables, detectar relaciones y seleccionar características útiles para el modelado.  \n",
        "\n",
        "3. **Construir modelos de ML**: implementar modelos supervisados (regresión, clasificación) utilizando librerías como `scikit-learn`.  \n",
        "\n",
        "4. **Evaluar desempeño**: comparar métricas como accuracy, precision, recall, F1-score y AUC para seleccionar los mejores enfoques.  \n",
        "\n",
        "5. **Generar conclusiones**: interpretar los resultados obtenidos y reflexionar sobre su impacto en la equidad educativa (LearnPlatform) y en la predicción de supervivencia (Titanic).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev-IiqqCniNr"
      },
      "source": [
        "\n",
        "\n",
        "## Instrucciones\n",
        "\n",
        "1. Completa tus datos personales en la celda correspondiente:\n",
        "\n",
        "   * **Nombre**: Aranxa Veloz\n",
        "   * **Rol USM**: 202210543-7\n",
        "(pido comprension por favor, me tocó ser vocal de mesa y perdí todo el fin de semana)\n",
        "2. Este archivo debe ser actualizado con tus respuestas y luego **subido a tu repositorio personal del curso**. Asegúrate de incluir todos los archivos necesarios para su ejecución (datos, imágenes, scripts, etc.).\n",
        "\n",
        "3. La evaluación de la tarea considerará los siguientes aspectos:\n",
        "\n",
        "   * Desarrollo correcto de las soluciones solicitadas.\n",
        "   * Claridad, legibilidad y calidad del código.\n",
        "   * Reproducibilidad: al ejecutar `Kernel → Restart Kernel and Run All Cells`, el notebook debe correr sin errores.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "Collapsed": "false",
        "id": "6S2Zpy_tniNs"
      },
      "source": [
        "## I.- LearnPlatform\n",
        "\n",
        "<img src=\"https://images.squarespace-cdn.com/content/v1/5cb36dc993a63270cfacbc2b/338586d4-5b1e-4b48-b2b2-408b8dd0f1a3/LearnPlatform+logo.png\" width = \"400\" align=\"center\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQPQs9X-niNt"
      },
      "source": [
        "### Introducción\n",
        "\n",
        "Nelson Mandela creía que la educación era el arma más poderosa para cambiar el mundo. Pero no todos los estudiantes tienen las mismas oportunidades de aprender. Es necesario promulgar políticas y planes efectivos para que la educación sea más equitativa, y tal vez su innovador análisis de datos ayude a revelar la solución.\n",
        "\n",
        "La investigación actual muestra que los resultados educativos están lejos de ser equitativos. El desequilibrio se vio agravado por la pandemia de COVID-19. Existe una necesidad urgente de comprender y medir mejor el alcance y el impacto de la pandemia en estas inequidades.\n",
        "\n",
        "La empresa de tecnología educativa LearnPlatform se fundó en 2014 con la misión de ampliar el acceso equitativo a la tecnología educativa para todos los estudiantes y profesores. Los distritos y estados utilizan el sistema integral de efectividad de la tecnología educativa de LearnPlatform para mejorar continuamente la seguridad, la equidad y la efectividad de su tecnología educativa. LearnPlatform lo hace generando una base de evidencia de lo que está funcionando y promulgándola en beneficio de los estudiantes, los profesores y los presupuestos.\n",
        "\n",
        "En esta competencia de análisis, trabajará para descubrir tendencias en el aprendizaje digital. Logre esto con un análisis de datos sobre cómo el compromiso con el aprendizaje digital se relaciona con factores como la demografía del distrito, el acceso a la banda ancha y las políticas y eventos a nivel estatal / nacional. Luego, envíe un notebook de Kaggle para proponer su mejor solución a estas desigualdades educativas.\n",
        "\n",
        "Sus presentaciones informarán las políticas y prácticas que cierran la brecha digital. Con una mejor comprensión de las tendencias de aprendizaje digital, puede ayudar a revertir la pérdida de aprendizaje a largo plazo entre los más vulnerables de Estados Unidos, haciendo que la educación sea más equitativa.\n",
        "\n",
        "### Planteamiento del problema\n",
        "La pandemia COVID-19 ha interrumpido el aprendizaje de más de 56 millones de estudiantes en los Estados Unidos. En la primavera de 2020, la mayoría de los gobiernos estatales y locales de los EE. UU. Cerraron las instituciones educativas para detener la propagación del virus. En respuesta, las escuelas y los maestros han intentado llegar a los estudiantes de forma remota a través de herramientas de aprendizaje a distancia y plataformas digitales. Hasta el día de hoy, las preocupaciones sobre la exacerbación de la brecha digital y la pérdida de aprendizaje a largo plazo entre los estudiantes más vulnerables de Estados Unidos continúan creciendo.\n",
        "\n",
        "### Desafío\n",
        "Los estudiantes deben explorar (1) el estado del aprendizaje digital en 2020 y (2) cómo la participación del aprendizaje digital se relaciona con factores como la demografía del distrito, el acceso a banda ancha y las políticas y eventos a nivel estatal/nacional.\n",
        "\n",
        "Le recomendamos que oriente el análisis con preguntas relacionadas con los temas descritos anteriormente (en negrita). A continuación se muestran algunos ejemplos de preguntas que se relacionan con el planteamiento de nuestro problema:\n",
        "\n",
        "* ¿Cuál es el panorama de la conectividad y el compromiso digitales en 2020?\n",
        "* ¿Cuál es el efecto de la pandemia de COVID-19 en el aprendizaje en línea y a distancia, y cómo podría evolucionar también en el futuro?\n",
        "* ¿Cómo cambia la participación de los estudiantes con los diferentes tipos de tecnología educativa durante el transcurso de la pandemia?\n",
        "* ¿Cómo se relaciona la participación de los estudiantes con las plataformas de aprendizaje en línea con las diferentes geografías? ¿Contexto demográfico (por ejemplo, raza/etnia, ESL, discapacidad de aprendizaje)? Contexto de aprendizaje? ¿Estatus socioeconómico?\n",
        "* ¿Se correlacionan ciertas intervenciones, prácticas o políticas estatales (por ejemplo, estímulo, reapertura, moratoria de desalojo) con el aumento o la disminución de la participación en línea?\n",
        "\n",
        "### Evaluación\n",
        "\n",
        "\n",
        "#### Claridad\n",
        "\n",
        "* ¿El autor presentó un hilo claro de preguntas o temas que motivaron su análisis?\n",
        "* ¿El autor documentó por qué/cómo se eligió y utilizó un conjunto de métodos para su análisis?\n",
        "* ¿Está documentado el notebook de una manera que sea fácilmente reproducible (p. Ej., Código, fuentes de datos adicionales, citas)?\n",
        "* ¿El notebook contiene visualizaciones de datos claras que ayuden a comunicar de manera eficaz los hallazgos del autor tanto a expertos como a no expertos?\n",
        "\n",
        "#### Precisión\n",
        "\n",
        "* ¿El autor procesó los datos (por ejemplo, fusionando) y/o fuentes de datos adicionales con precisión?\n",
        "* ¿La metodología utilizada en el análisis es apropiada y razonable?\n",
        "* ¿Son razonables y convincentes las interpretaciones basadas en el análisis y la visualización?\n",
        "\n",
        "#### Creatividad\n",
        "\n",
        "* ¿El notebook ayuda al lector a aprender algo nuevo o lo desafía a pensar de una manera nueva?\n",
        "* ¿El notebook aprovecha métodos novedosos y/o visualizaciones que ayudan a revelar información a partir de datos y/o comunicar hallazgos?\n",
        "* ¿El autor utilizó fuentes de datos públicas adicionales en su análisis?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1jwuv8RniNt"
      },
      "source": [
        "### Hints\n",
        "\n",
        "* Esto corresponde a un desafio de Kaggle ([link](https://www.kaggle.com/c/learnplatform-covid19-impact-on-digital-learning/overview/description)).\n",
        "*  La información respecto a los datos, lo pueden encontrar en el siguiente [link](https://www.kaggle.com/c/learnplatform-covid19-impact-on-digital-learning/data).\n",
        "* A modo de inspiración, pueden ocupar algunos gráficos de otros participantes del desafío ([link](https://www.kaggle.com/c/learnplatform-covid19-impact-on-digital-learning/code))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7HtG2yIaniNu",
        "outputId": "56058e94-5b2c-4759-8afe-a7bd9a9ecf3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Cuando aparezca el diálogo, selecciona tu 'kaggle.json' (Kaggle > Settings > Account > Create New API Token).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7f44690c-2882-495b-937e-4b3cab68e08f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7f44690c-2882-495b-937e-4b3cab68e08f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/datasets/metadata/learnplatform/covid19-impact-on-digital-learning\n",
            "unzip:  cannot find or open /content/data_learnplatform/covid19-impact-on-digital-learning.zip, /content/data_learnplatform/covid19-impact-on-digital-learning.zip.zip or /content/data_learnplatform/covid19-impact-on-digital-learning.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "# 1) Instalar Kaggle y subir el token (aparecerá un diálogo para elegir archivo)\n",
        "!pip -q install kaggle\n",
        "from google.colab import files\n",
        "print(\">> Cuando aparezca el diálogo, selecciona tu 'kaggle.json' (Kaggle > Settings > Account > Create New API Token).\")\n",
        "uploaded = files.upload()  # <-- AQUÍ seleccionas 'kaggle.json' desde tu PC\n",
        "\n",
        "# 2) Guardar el token en la ruta correcta y dar permisos\n",
        "import os\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "os.rename(\"kaggle.json\", \"/root/.kaggle/kaggle.json\")\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 0o600)\n",
        "\n",
        "# 3) Descargar y descomprimir el dataset LearnPlatform en Colab\n",
        "!mkdir -p /content/data_learnplatform\n",
        "!kaggle datasets download -d learnplatform/covid19-impact-on-digital-learning -p /content/data_learnplatform\n",
        "!unzip -o \"/content/data_learnplatform/covid19-impact-on-digital-learning.zip\" -d \"/content/data_learnplatform\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWZo1SMZniNw"
      },
      "source": [
        "## II.- Titanic - Machine Learning from Disaster\n",
        "\n",
        "<img src=\"https://i.pinimg.com/originals/8c/ef/e7/8cefe799c4d5d2ad4ad7f6524d3838f4.png\" width = \"400\" align=\"center\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDaOXof-niNx"
      },
      "source": [
        "El desafío **Titanic - Machine Learning from Disaster** en [Kaggle](https://www.kaggle.com/competitions/titanic/overview/description) invita a predecir qué pasajeros sobrevivieron al naufragio del Titanic mediante un modelo de machine learning. Utiliza datos reales de los pasajeros, como su nombre, edad, género y clase socioeconómica, para explorar patrones de supervivencia y construir un modelo predictivo. Este es uno de los desafíos más populares de Kaggle y un excelente punto de partida para aprender sobre machine learning y análisis de datos.\n",
        "\n",
        "### Pasos para participar:\n",
        "\n",
        "1. **Unirse a la competencia**:\n",
        "   - [Crea una cuenta o inicia sesión en Kaggle](https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic) y acepta las reglas para acceder a los datos de la competencia.\n",
        "   \n",
        "2. **Descargar y explorar los datos**:\n",
        "   - Descarga los archivos `train.csv` y `test.csv` desde la [página de datos](https://www.kaggle.com/competitions/titanic/data).\n",
        "   - `train.csv` contiene información de 891 pasajeros, incluyendo si sobrevivieron o no (columna `Survived`). En `test.csv`, se oculta esta columna para que tu modelo prediga la supervivencia de 418 pasajeros adicionales.\n",
        "\n",
        "3. **Desarrollar el modelo**:\n",
        "   - Usa `train.csv` para explorar y descubrir patrones, luego entrena un modelo de machine learning que pueda predecir la supervivencia en `test.csv`. Un recurso útil para aprender es el [tutorial de Alexis Cook](https://www.kaggle.com/alexisbcook/titanic-tutorial), que explica paso a paso cómo hacer tu primera predicción.\n",
        "   - Puedes explorar notebooks de otros participantes para inspiración y técnicas avanzadas en la [sección de notebooks](https://www.kaggle.com/c/titanic/notebooks).\n",
        "\n",
        "4. **Realizar una predicción y enviar tu archivo**:\n",
        "   - El archivo CSV de predicciones debe tener dos columnas: `PassengerId` y `Survived`. Puedes consultar un ejemplo en el archivo `gender_submission.csv` disponible en la [página de datos](https://www.kaggle.com/competitions/titanic/data).\n",
        "   - Sube tu archivo en la sección de envíos y revisa tu puntaje de precisión, que mide el porcentaje de pasajeros que tu modelo predijo correctamente.\n",
        "\n",
        "5. **Revisar el leaderboard y mejorar el modelo**:\n",
        "   - Ve tu posición en el [leaderboard](https://www.kaggle.com/c/titanic/leaderboard) y mejora tu modelo basándote en ideas de los foros o pruebas adicionales.\n",
        "\n",
        "### Ayuda y recursos adicionales:\n",
        "\n",
        "- [Foro de discusión del Titanic](https://www.kaggle.com/c/titanic/discussion): Un espacio donde puedes hacer preguntas y ver consejos de otros participantes.\n",
        "- [Vídeo sobre la jerga de Kaggle](https://www.youtube.com/watch?v=sEJHyuWKd-s) por Dr. Rachael Tatman, para entender mejor los términos comunes en Kaggle.\n",
        "- [Notebooks de la competencia](https://www.kaggle.com/c/titanic/notebooks): Revisa notebooks compartidos para ver cómo otros abordan el desafío.\n",
        "\n",
        "Este desafío es ideal para principiantes en machine learning y permite practicar desde la limpieza de datos hasta el desarrollo y evaluación de modelos."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3."
      ],
      "metadata": {
        "id": "nyQVC1l7obOc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_Q4UQJzCniNx",
        "outputId": "f32a8f66-563e-4f41-ee5d-2126e4de9fd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest  Acc:0.810  Prec:0.830  Rec:0.638  F1:0.721\n",
            "Matriz de confusión:\n",
            " [[101   9]\n",
            " [ 25  44]]\n",
            "Listo ✅ -> /content/data_titanic/submission.csv\n",
            "   PassengerId  Survived\n",
            "0          892         0\n",
            "1          893         0\n",
            "2          894         0\n",
            "3          895         0\n",
            "4          896         1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# 1) Cargar datos\n",
        "DATA_TIT = \"/content/data_titanic\"\n",
        "train = pd.read_csv(f\"{DATA_TIT}/train.csv\")\n",
        "test  = pd.read_csv(f\"{DATA_TIT}/test.csv\")\n",
        "\n",
        "# 2) Preprocesamiento simple\n",
        "cols = [\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\"]\n",
        "\n",
        "X = train[cols].copy()\n",
        "y = train[\"Survived\"].astype(int)\n",
        "\n",
        "# Medianas para rellenar nulos\n",
        "age_med  = X[\"Age\"].median()\n",
        "fare_med = X[\"Fare\"].median()\n",
        "\n",
        "# Mapear Sex y rellenar nulos\n",
        "X[\"Sex\"]  = X[\"Sex\"].map({\"male\":0, \"female\":1})\n",
        "X[\"Age\"]  = X[\"Age\"].fillna(age_med)\n",
        "X[\"Fare\"] = X[\"Fare\"].fillna(fare_med)\n",
        "\n",
        "# Mismo tratamiento en test\n",
        "X_test = test[cols].copy()\n",
        "X_test[\"Sex\"]  = X_test[\"Sex\"].map({\"male\":0, \"female\":1})\n",
        "X_test[\"Age\"]  = X_test[\"Age\"].fillna(age_med)\n",
        "X_test[\"Fare\"] = X_test[\"Fare\"].fillna(fare_med)\n",
        "\n",
        "# 3) Validación rápida\n",
        "X_tr, X_va, y_tr, y_va = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=200, max_depth=6, random_state=0)\n",
        "model.fit(X_tr, y_tr)\n",
        "\n",
        "y_hat = model.predict(X_va)\n",
        "acc = accuracy_score(y_va, y_hat)\n",
        "prec = precision_score(y_va, y_hat)\n",
        "rec = recall_score(y_va, y_hat)\n",
        "f1 = f1_score(y_va, y_hat)\n",
        "cm = confusion_matrix(y_va, y_hat)\n",
        "\n",
        "print(f\"RandomForest  Acc:{acc:.3f}  Prec:{prec:.3f}  Rec:{rec:.3f}  F1:{f1:.3f}\")\n",
        "print(\"Matriz de confusión:\\n\", cm)\n",
        "\n",
        "# 4) Entrenar con todo y generar submission\n",
        "model.fit(X, y)\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "submission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": pred})\n",
        "submission.to_csv(f\"{DATA_TIT}/submission.csv\", index=False)\n",
        "print(\"Listo ✅ ->\", f\"{DATA_TIT}/submission.csv\")\n",
        "print(submission.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4."
      ],
      "metadata": {
        "id": "hJqKkHJVo--6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, numpy as np, pathlib, subprocess, re\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "DATA_TIT = \"/content/data_titanic\"\n",
        "COMP     = \"titanic\"\n",
        "OUT_P4   = f\"{DATA_TIT}/submission_p4_intento.csv\"\n",
        "MSG_P4   = \"Punto4 intento RF depth=8\"\n",
        "\n",
        "# Cargar\n",
        "train = pd.read_csv(f\"{DATA_TIT}/train.csv\")\n",
        "test  = pd.read_csv(f\"{DATA_TIT}/test.csv\")\n",
        "\n",
        "# Prepro simple\n",
        "cols = [\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\"]\n",
        "X = train[cols].copy(); y = train[\"Survived\"].astype(int)\n",
        "X[\"Sex\"]  = X[\"Sex\"].map({\"male\":0,\"female\":1})\n",
        "X[\"Age\"]  = X[\"Age\"].fillna(X[\"Age\"].median())\n",
        "X[\"Fare\"] = X[\"Fare\"].fillna(X[\"Fare\"].median())\n",
        "\n",
        "X_test = test[cols].copy()\n",
        "X_test[\"Sex\"]  = X_test[\"Sex\"].map({\"male\":0,\"female\":1})\n",
        "X_test[\"Age\"]  = X_test[\"Age\"].fillna(X[\"Age\"].median())\n",
        "X_test[\"Fare\"] = X_test[\"Fare\"].fillna(X[\"Fare\"].median())\n",
        "\n",
        "model_p4 = RandomForestClassifier(n_estimators=400, max_depth=8, random_state=0, n_jobs=-1)\n",
        "model_p4.fit(X, y)\n",
        "pred_p4 = model_p4.predict(X_test).astype(int)\n",
        "\n",
        "# CSV intento Punto 4\n",
        "sub_p4 = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": pred_p4})\n",
        "assert list(sub_p4.columns) == [\"PassengerId\",\"Survived\"] and set(sub_p4[\"Survived\"].unique()) <= {0,1}\n",
        "sub_p4.to_csv(OUT_P4, index=False)\n",
        "print(\"CSV Punto 4 listo:\", OUT_P4); print(sub_p4.head())\n",
        "\n",
        "if not pathlib.Path(\"/root/.kaggle/kaggle.json\").exists():\n",
        "    raise RuntimeError(\"Faltan credenciales en ~/.kaggle/kaggle.json\")\n",
        "print(\"\\nSubiendo intento del Punto 4…\")\n",
        "!kaggle competitions submit -c {COMP} -f {OUT_P4} -m \"{MSG_P4}\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-EQax2FQpBm8",
        "outputId": "ebe3c426-fd8f-4a0d-999a-1786fa6ea843",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV Punto 4 listo: /content/data_titanic/submission_p4_intento.csv\n",
            "   PassengerId  Survived\n",
            "0          892         0\n",
            "1          893         0\n",
            "2          894         0\n",
            "3          895         0\n",
            "4          896         0\n",
            "\n",
            "Subiendo intento del Punto 4…\n",
            "100% 2.77k/2.77k [00:00<00:00, 4.55kB/s]\n",
            "Successfully submitted to Titanic - Machine Learning from Disaster"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El puntaje fue 0.76555"
      ],
      "metadata": {
        "id": "D2u1wVa3pZKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5."
      ],
      "metadata": {
        "id": "2ec03hw2pdc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#re-submit del baseline (mejor puntaje)\n",
        "import pandas as pd, pathlib, subprocess\n",
        "\n",
        "DATA_TIT = \"/content/data_titanic\"\n",
        "COMP     = \"titanic\"\n",
        "OUT_BEST = f\"{DATA_TIT}/submission.csv\"  # generado en el Punto 3\n",
        "MSG_P5   = \"Punto5 baseline (mejor score)\"\n",
        "\n",
        "# Verificar el archivo baseline\n",
        "sub_best = pd.read_csv(OUT_BEST)\n",
        "assert list(sub_best.columns) == [\"PassengerId\",\"Survived\"], \"Formato incorrecto.\"\n",
        "assert set(sub_best[\"Survived\"].unique()) <= {0,1}, \"Survived debe ser 0 o 1.\"\n",
        "print(\" Archivo baseline verificado:\", OUT_BEST)\n",
        "print(sub_best.head())\n",
        "\n",
        "# Subir automáticamente a Kaggle\n",
        "if not pathlib.Path(\"/root/.kaggle/kaggle.json\").exists():\n",
        "    raise RuntimeError(\"Faltan credenciales en ~/.kaggle/kaggle.json\")\n",
        "\n",
        "print(\"\\nSubiendo baseline (mejor modelo) a Kaggle…\")\n",
        "out = subprocess.run(\n",
        "    [\"kaggle\", \"competitions\", \"submit\", \"-c\", COMP, \"-f\", OUT_BEST, \"-m\", MSG_P5],\n",
        "    capture_output=True, text=True\n",
        ")\n",
        "print(out.stdout)\n",
        "print(\" Envío del Punto 5 realizado correctamente.\")\n"
      ],
      "metadata": {
        "id": "11_CY4YcpfK7",
        "outputId": "deaa25cc-14b5-49ad-bd86-7978f19d07bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Archivo baseline verificado: /content/data_titanic/submission.csv\n",
            "   PassengerId  Survived\n",
            "0          892         0\n",
            "1          893         0\n",
            "2          894         0\n",
            "3          895         0\n",
            "4          896         1\n",
            "\n",
            "Subiendo baseline (mejor modelo) a Kaggle…\n",
            "Successfully submitted to Titanic - Machine Learning from Disaster\n",
            " Envío del Punto 5 realizado correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El puntaje obtenido fue 0.77990"
      ],
      "metadata": {
        "id": "PCZaPBIoqL9u"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}